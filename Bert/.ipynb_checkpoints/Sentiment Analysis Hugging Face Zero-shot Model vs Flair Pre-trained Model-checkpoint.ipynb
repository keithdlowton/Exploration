{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "360fe721",
   "metadata": {},
   "source": [
    "### Sentiment Analysis Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87586d16",
   "metadata": {},
   "source": [
    "Hugging Face zero-shot sentiment analysis uses zero-shot learning (ZSL), which refers to building a model and using it to make predictions on tasks the model was not trained to do. It can be used on any text classification task, including but not limited to sentiment analysis and topic modeling.  \n",
    "  \n",
    "Zero-shot sentiment analysis from Hugging Face is a use case of the Hugging Face zero-shot text classification model. It is a Natural Language Inference (NLI) model where two sequences are compared to see if they contradict each other, entail each other, or are neutral (neither contradict nor entail).  \n",
    "  \n",
    "When using the Hugging Face zero-shot sentiment analysis, we will have the text as the premise and the sentiment labels such as positive and negative as hypotheses. If the model predicts that a text document entails positive, then the document is predicted to have a positive sentiment. Otherwise, the document is predicted to have a negative sentiment.  \n",
    "  \n",
    "The Flair pre-trained sentiment model is a text classification model explicitly built for predicting sentiments. The modeling dataset set is the IMDB, so it may work better for documents that are similar to the IMDB data than the documents that are quite different from IMDB data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbadd8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data processing\n",
    "import pandas as pd\n",
    "\n",
    "# Hugging Face model\n",
    "from transformers import pipeline\n",
    "\n",
    "# Import flair pre-trained sentiment model\n",
    "from flair.models import TextClassifier\n",
    "classifier = TextClassifier.load('en-sentiment')\n",
    "\n",
    "# Import flair Sentence to process input text\n",
    "from flair.data import Sentence\n",
    "\n",
    "# Import accuracy_score to check performance\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "511fb529",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Read in data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m amz_review \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment labelled sentences/amazon_cells_labelled.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m, names\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreview\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Take a look at the data\u001b[39;00m\n\u001b[1;32m      5\u001b[0m amz_review\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Read in data\n",
    "amz_review = pd.read_csv('sentiment labelled sentences/amazon_cells_labelled.txt', sep='\\t', names=['review', 'label'])\n",
    "\n",
    "# Take a look at the data\n",
    "amz_review.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46441031",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4cf1d17d",
   "metadata": {},
   "source": [
    "### Hugging Face Zero-shot Sentiment Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b845a7",
   "metadata": {},
   "source": [
    "Firstly, the pipeline is defined:  \n",
    "  \n",
    "* task describes the task for the pipeline. The task name we use is zero-shot-classification.  \n",
    "* model is the model name for the prediction used in the pipeline. You can find the full list of available models for zero-shot classification on the Hugging Face website. At the time this tutorial was created in January 2023, the bart-large-mnli by Facebook(Meta) is the model with the highest number of downloads and likes, so we will use it for the pipeline.  \n",
    "* device defines the device type. device=0 means that we are using GPU for the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd3afde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pipeline\n",
    "classifier = pipeline(task=\"zero-shot-classification\", \n",
    "                      model=\"facebook/bart-large-mnli\",\n",
    "                      device=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a208e3e4",
   "metadata": {},
   "source": [
    "After defining the pipeline the data is processed and the sentiments are predicted by the pipeline.  \n",
    "  \n",
    "* Firstly, the reviews are put into a list for the pipeline.  \n",
    "* Then, the candidate labels are defined. We set two candidate labels, positive and negative.  \n",
    "* After that, the hypothesis template is defined. The default template is used by the Hugging Face pipeline is This example is {}. We use a hypothesis template that is more specific to the sentiment analysis The sentiment of this review is {}. and it helps to improve the results.  \n",
    "* Finally, the text, the candidate labels, and the hypothesis template are passed into the zero-shot classification pipeline called classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d47d25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put reviews in a list\n",
    "sequences = amz_review['review'].to_list()\n",
    "\n",
    "# Define the candidate labels \n",
    "candidate_labels = [\"positive\", \"negative\"]\n",
    "\n",
    "# Set the hyppothesis template\n",
    "hypothesis_template = \"The sentiment of this review is {}.\"\n",
    "\n",
    "# Prediction results\n",
    "hf_prediction = classifier(sequences, candidate_labels, hypothesis_template=hypothesis_template)\n",
    "\n",
    "# Save the output as a dataframe\n",
    "hf_prediction = pd.DataFrame(hf_prediction)\n",
    "\n",
    "# Take a look at the data\n",
    "hf_prediction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc86d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The column for the predicted topic\n",
    "hf_prediction['hf_prediction'] = hf_prediction['labels'].apply(lambda x: x[0])\n",
    "\n",
    "# Map sentiment values\n",
    "hf_prediction['hf_prediction'] = hf_prediction['hf_prediction'].map({'positive': 1, 'negative': 0})\n",
    "\n",
    "# The column for the score of predicted topic\n",
    "hf_prediction['hf_predicted_score'] = hf_prediction['scores'].apply(lambda x: x[0])\n",
    "\n",
    "# The actual labels\n",
    "hf_prediction['true_label'] = amz_review['label']\n",
    "\n",
    "# Drop the columns that we do not need\n",
    "hf_prediction = hf_prediction.drop(['labels', 'scores'], axis=1)\n",
    "\n",
    "# Take a look at the data\n",
    "hf_prediction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876fe296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Actual and Predicted\n",
    "accuracy_score(hf_prediction['hf_prediction'], hf_prediction['true_label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32442a5",
   "metadata": {},
   "source": [
    "### Flair Pretrained Sentiment Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2994b733",
   "metadata": {},
   "source": [
    "Letâ€™s define a function that takes a review as input and the score and the predicted label as outputs.  \n",
    "  \n",
    "* Firstly, the review text is passed into the Sentence function to get tokenized.  \n",
    "* Then, we use the .predict() to make sentiment predictions.  \n",
    "* After the prediction, we can extract score and value from the sentence. value is the predicted sentiment label, and score is how confident the model is about the prediction.  \n",
    "* Finally, the function output the score and the value for the input review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b9ce73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
